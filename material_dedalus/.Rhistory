first_row <- resumen_evolucion[[]][1]
first_row <- head(resumen_evolucion,1)
first_row
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AnalisisDeDatos.R", echo=TRUE)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AnalisisDeDatos.R", echo=TRUE)
View(resumen_evolucion)
View(resumen_evolucion)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AnalisisDeDatos.R", echo=TRUE)
# 3. Eliminar la última columna
resumen_evolucion$`NA` <- NULL
resumen_evolucion |>
filter(is.na(resumen_evolucion$Hora))
resumen_evolucion$Hora |>
filter(is.na())
which(resumen_evolucion$Hora)
lapply(resumen_evolucion$Hora, function(x) which(is.nan(x)))
resumen_evolucion[indices]
resumen_evolucion[indices,]
indices <- lapply(resumen_evolucion$Hora, function(x) which(is.nan(x)))
resumen_evolucion[indices,]
class(resumen_evolucion)
resumen_evolucion[apply(is.na(df), 1, any),]
indices <- lapply(resumen_evolucion$Hora, function(x) which(is.nan(x)))
resumen_evolucion[apply(is.na(resumen_evolucion), 1, any),]
resumen_evolucion[1]
resumen_evolucion[1,]
resumen_evolucion |>
filter(is.nan(resumen_evolucion$Hora))
library(tidyverse)
resumen_evolucion |>
filter(is.nan(resumen_evolucion$Hora))
resumen_evolucion |>
filter(is.nan(resumen_evolucion$Hora))
class(resumen_evolucion[[3]][19])
class(resumen_evolucion[[3]][19])
resumen_evolucion[[3]][19]
class(resumen_evolucion[[3]][22])
resumen_evolucion[[3]][22]
class(resumen_evolucion[[3]][23])
resumen_evolucion[[3]][23]
resumen_evolucion |>
filter(PacienteID=18)
resumen_evolucion_process <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/resumen_evolucion_process.csv")
View(resumen_evolucion_process)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AnalisisDeDatos.R", echo=TRUE)
summarise(resumen_evolucion_process)
View(resumen_evolucion_process)
resumen_evolucion_process <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/resumen_evolucion_process.csv")
library(tidyverse)
summarise(resumen_evolucion_process)
#
# # 3. Eliminar la última columna
# resumen_evolucion$`NA` <- NULL
#
# class(resumen_evolucion)
#
# resumen_evolucion |>
#   filter(PacienteID=18)
#
# class(resumen_evolucion[[3]][23])
resumen_evolucion_process
#
# # 3. Eliminar la última columna
# resumen_evolucion$`NA` <- NULL
#
# class(resumen_evolucion)
#
# resumen_evolucion |>
#   filter(PacienteID=18)
#
# class(resumen_evolucion[[3]][23])
class(resumen_evolucion_process)
resumen_evolucion_process |>
summarise()
library(tidyverse)
resumen_evolucion_process |>
str()
resumen_evolucion_process |>
filter(is.integer())
resumen_evolucion_process$NA. <- NULL
# # Exportar el dataset modificado como un archivo CSV
write.csv(resumen_evolucion, "resumen_evolucion_process.csv", row.names = FALSE)
colnames(resumen_evolucion_process)
colnames(resumen_lab_iniciales)
colnames(resumen_medicacion)
colnames(resumen_notas)
colnames(resumen_pacientes)
colnames(resumen_procedimientos)
View(resumen_evolucion)
resumen_evolucion <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/resumen_evolucion.csv", header=FALSE)
View(resumen_evolucion)
library(dplyr)
library(readr)
library(purrr)  # Lee múltiples archivos a la vez
# Definir la ruta de los archivos
ruta_archivos <- "C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/"
# Obtener lista de archivos CSV en la carpeta
archivos_csv <- list.files(path = ruta_archivos, pattern = "\\.csv$", full.names = TRUE)
archivos_csv
library(dplyr)
library(readr)
library(purrr)  # Lee múltiples archivos a la vez
# Definir la ruta de los archivos
ruta_archivos <- "C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/"
# Obtener lista de archivos CSV en la carpeta
archivos_csv <- list.files(path = ruta_archivos, pattern = "\\.csv$", full.names = TRUE)
archivos_csv
# Leer y combinar todos los archivos en un solo DataFrame
df <- map_df(archivos_csv, read_csv)
df
View(df)
df_agg <- df %>%
group_by(PacienteID) %>%
summarise(
Edad_Promedio = mean(Edad, na.rm = TRUE),  # Calcular la edad promedio
Diagnosticos = paste(unique(Diagnóstico), collapse = "; "),  # Unir diagnósticos únicos
Primera_Fecha = min(Fecha, na.rm = TRUE)  # Obtener la fecha más antigua
)
source("~/.active-rstudio-document", echo=TRUE)
View(df)
View(resumen_lab_iniciales)
View(resumen_lab_iniciales)
View(resumen_notas)
View(resumen_pacientes)
View(resumen_pacientes)
View(resumen_procedimientos)
View(resumen_procedimientos)
source("~/.active-rstudio-document", echo=TRUE)
View(df)
clr
clean
cln
ruta_archivos <- "C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/DataSetIndividuales/"
# Obtener lista de archivos CSV en la carpeta
archivos_csv <- list.files(path = ruta_archivos, pattern = "\\.csv$", full.names = TRUE)
archivos_csv
df <- map_df(archivos_csv, read_csv)
df_agg <- df %>%
group_by(PacienteID) %>%
summarise(
Edad_Promedio = mean(Edad, na.rm = TRUE),  # Calcular la edad promedio
Diagnosticos = paste(unique(Diagnóstico), collapse = "; "),  # Unir diagnósticos únicos
Primera_Fecha = min(Fecha, na.rm = TRUE)  # Obtener la fecha más antigua
)
# Definir la ruta de los archivos
ruta_archivos <- "ruta/a/tus/csv/"
# Obtener lista de archivos CSV en la carpeta
archivos_csv <- list.files(path = ruta_archivos, pattern = "\\.csv$", full.names = TRUE)
# Leer todos los archivos y asegurarse de que todas las columnas sean incluidas
df_list <- map(archivos_csv, ~ read_csv(.x, show_col_types = FALSE))
# Unir todos los archivos en un solo DataFrame, asegurando todas las columnas
df <- bind_rows(df_list, .id = "Archivo_Origen")  # Agrega la columna de origen del archivo (opcional)
df
source("~/.active-rstudio-document", echo=TRUE)
View(df_final)
View(df_final)
write_csv(df_final, "resumen_pacientes_combinados.csv")
resumen_evolucion_process <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/resumen_evolucion_process.csv")
View(resumen_evolucion_process)
library(tidyverse)
library(jsonlite)
View(resumen_evolucion_process)
|>
df_agg <- resumen_evolucion_process |>
group_by(PacienteID) |>
summarise(
Diagnosticos = toJSON(list(na.omit(unique(Diagnostico)))),  # Eliminar NA antes de agrupar
Tratamientos = toJSON(list(na.omit(unique(Tratamiento))))   # Eliminar NA antes de agrupar
)
df_agg
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AgrupacionDatosJSON.R", echo=TRUE)
colnames(resumen_evolucion_process)
colnames(resumen_evolucion_process)
df_agg <- resumen_evolucion_process |>
group_by(PacienteID) |>
summarise(
across(
.cols = -PacienteID,  # Excluir la columna PacienteID
.fns = ~ toJSON(list(na.omit(unique(.)))),  # Convertir cada columna a JSON-like
.names = "{.col}_json"  # Crear un nombre nuevo para cada columna agregada
)
)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AgrupacionDatosJSON.R", echo=TRUE)
View(df_agg)
resumen_evolucion_process <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/resumen_evolucion_process.csv")
df <- resumen_evolucion_process
df$Fecha <- paste(df$Fecha,df$Hora,sep= "-")
df$Hora <- NULL
View(df)
df_agg <- df %>%
group_by(PacienteID) %>%
summarise(
DatosPorFecha = toJSON(
list(
# Agrupar por FechaHora
`FechaHora` = list(
lapply(
split(df, df$FechaHora),  # Agrupar por FechaHora
function(x) {
# Extraemos los valores de laboratorio y los agrupamos
as.list(
across(
.cols = -c(PacienteID,Fecha),  # Filtrar por las columnas de laboratorio
.fns = ~ unique(na.omit(.))  # Obtener valores únicos y omitir NAs
)
)
}
)
)
)
)
)
df_agg <- df |>
group_by(PacienteID)
View(df_agg)
# Extraemos los valores de laboratorio y los agrupamos
list(
across(
.cols = -c(PacienteID,Fecha),  # Filtrar por las columnas de laboratorio
.fns = ~ unique(na.omit(.))  # Obtener valores únicos y omitir NAs
)
)
pacientes1 <-  df |>
filter(PacienteID = 1)
pacientes1 <-  df |>
filter(PacienteID == 1)
View(pacientes1)
df_agg <- df |>
group_by(PacienteID) |>
summarise(
DatosPorFecha = toJSON(
list(
# Agrupar por FechaHora
`FechaHora` = list(
lapply(
split(df, df$FechaHora),  # Agrupar por FechaHora
function(x) {
# Extraemos los valores de laboratorio y los agrupamos
list(
across(
.cols = -c(PacienteID,Fecha),  # Filtrar por las columnas de laboratorio
.fns = ~ unique(na.omit(.))  # Obtener valores únicos y omitir NAs
)
)
}
)
)
)
)
)
df_agg <- df %>%
group_by(PacienteID) %>%
summarise(
DatosPorFecha = toJSON(
list(
`FechaHora` = lapply(
split(., .$FechaHora),  # Ahora, dividir por FechaHora dentro de cada grupo PacienteID
function(x) {
# Extraer los valores de laboratorio y agrupados
as.list(
across(
.cols = -c(PacienteID, FechaHora),  # Excluir columnas no deseadas (PacienteID y FechaHora)
.fns = ~ unique(na.omit(.))  # Obtener valores únicos y omitir NAs
)
)
}
)
)
)
)
df_agg <- df %>%
group_by(PacienteID, FechaHora) %>%
summarise(
DatosLaboratorio = list(
across(
.cols = -c(PacienteID, FechaHora),  # Excluye PacienteID y FechaHora
.fns = ~ unique(na.omit(.))  # Obtén los valores únicos y elimina NA
)
),
.groups = "drop"  # Para evitar mantener el agrupamiento después
) %>%
group_by(PacienteID) %>%
summarise(
DatosPorFecha = toJSON(
list(
`FechaHora` = lapply(split(., .$FechaHora), function(x) {
as.list(x$DatosLaboratorio)
})
)
),
.groups = "drop"
)
df_agg <- df %>%
group_by(PacienteID, Fecha) %>%
summarise(
DatosLaboratorio = list(
across(
.cols = -c(PacienteID, Fecha),  # Excluye PacienteID y FechaHora
.fns = ~ unique(na.omit(.))  # Obtén los valores únicos y elimina NA
)
),
.groups = "drop"  # Para evitar mantener el agrupamiento después
) %>%
group_by(PacienteID) %>%
summarise(
DatosPorFecha = toJSON(
list(
`FechaHora` = lapply(split(., .$FechaHora), function(x) {
as.list(x$DatosLaboratorio)
})
)
),
.groups = "drop"
)
df_agg <- df %>%
group_by(PacienteID, Fecha) %>%
summarise(
DatosLaboratorio = list(
across(
.cols = -c(PacienteID, Fecha),  # Excluye PacienteID y FechaHora
.fns = ~ unique(na.omit(.))  # Obtén los valores únicos y elimina NA
)
),
.groups = "drop"  # Para evitar mantener el agrupamiento después
) %>%
group_by(PacienteID) %>%
summarise(
DatosPorFecha = toJSON(
list(
`FechaHora` = lapply(split(., .$Fecha), function(x) {
as.list(x$DatosLaboratorio)
})
)
),
.groups = "drop"
)
colnames(df)
colnames(df(-2:))
colnames(df)(-2)
colnames(df)(-2:)
colnames(df)[[-2]]
class(colnames(df))
colnames(df)[-c(1, 2)]
json_por_fila <- lapply(df[-c(1, 2)], toJSON())
json_por_fila <- lapply(df[-c(1, 2)], function(fila) {
toJSON(as.list(fila), auto_unbox = TRUE)
})
View(json_por_fila)
class(json_por_fila)
mutate(df, JSON=json_por_fila)
View(df)
jsondataframe <- mutate(df, JSON=json_por_fila)
View(jsondataframe)
df_no_na <- df
df_no_na[is.na(df_no_na)] <- NULL
df_no_na <- df
df_no_na[is.na(df_no_na)] <- NULL
View(df_no_na)
df_no_na <- df
df_no_na[is.na(df_no_na)] <- NULL
df_no_na <- df
df_no_na[is.na(df_no_na)] <- NULL
json_por_fila <- lapply(df_no_na[-c(1, 2)],1, function(fila) {
toJSON(as.list(fila), auto_unbox = TRUE)
})
json_por_fila <- lapply(df[-c(1, 2)], function(fila) {
toJSON(as.list(fila), auto_unbox = TRUE,na="none")
})
json_por_fila <- lapply(df[-c(1, 2)], function(fila) {
toJSON(as.list(fila), auto_unbox = TRUE,na="null")
})
class(json_por_fila)
jsondataframe <- mutate(df_no_na, JSON=json_por_fila)
View(df)
json_list <- apply(df[-c(PacienteID,Fecha)], 1, function(row) {
json <- toJSON(as.list(row), auto_unbox = TRUE)
return(json)
})
json_list <- apply(df[-c(PacienteID,Fecha)], 1, function(row) {
json <- toJSON(as.list(row), auto_unbox = TRUE)
return(json)
})
df
json <- toJSON(as.list(row), auto_unbox = TRUE)
json_list <- apply(df[-c(df$PacienteID,df$Fecha)], 1, function(row) {
json <- toJSON(as.list(row), auto_unbox = TRUE)
})
json_por_fila <- apply(df[-c(1, 2)], function(fila) {
toJSON(as.list(row), auto_unbox = TRUE,na="null")
})
json_por_fila <- apply(df[-c(1, 2)],1, function(fila) {
toJSON(as.list(row), auto_unbox = TRUE,na="null")
})
json_por_fila <- lapply(df[-c(1, 2)], function(fila) {
toJSON(as.list(row), auto_unbox = TRUE,na="null")
})
# Convertir la fila a lista y luego a JSON
json <- toJSON(as.list(row), auto_unbox = TRUE)
df
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/material_dedalus/AgrupacionDatosJSON.R", echo=TRUE)
json_result <- toJSON(df[-c(1,2)], pretty = TRUE)
# Mostrar el resultado JSON
cat(json_result)
df_json <- mutate(df,JSON=json_result)
View(df_json)
View(df_json)
json_result_2 <- toJSON(df[c(2,30)], pretty = TRUE)
json_result_2 <- toJSON(df_json[c(2,30)], pretty = TRUE)
df_json$JSON <- json_result_2
cat(json_result_2)
json_result <- toJSON(df[-c(1)], pretty = TRUE)
# Mostrar el resultado JSON
cat(json_result)
df_json$JSON <- json_result
df_grouped <- df %>%
group_by(PacienteID) %>%
summarise(
registros = list(
data.frame(
Fecha = Fecha,
Hora = Hora,
PresionSistolica = PresionSistolica,
PresionDiastolica = PresionDiastolica,
FrecuenciaCardiaca = FrecuenciaCardiaca,
Temperatura = Temperatura,
FrecuenciaRespiratoria = FrecuenciaRespiratoria,
SaturacionOxigeno = SaturacionOxigeno,
Glucosa = Glucosa,
Leucocitos = Leucocitos,
Hemoglobina = Hemoglobina,
Plaquetas = Plaquetas,
Colesterol = Colesterol,
HDL = HDL,
LDL = LDL,
Trigliceridos = Trigliceridos,
Sodio = Sodio,
Potasio = Potasio,
Cloro = Cloro,
Creatinina = Creatinina,
Urea = Urea,
AST = AST,
ALT = ALT,
Bilirrubina = Bilirrubina,
pH = pH,
pCO2 = pCO2,
pO2 = pO2,
HCO3 = HCO3,
Lactato = Lactato
)
),
.groups = "drop"
)
df_grouped <- df %>%
group_by(PacienteID) %>%
summarise(
registros = list(
data.frame(
Fecha = Fecha,
PresionSistolica = PresionSistolica,
PresionDiastolica = PresionDiastolica,
FrecuenciaCardiaca = FrecuenciaCardiaca,
Temperatura = Temperatura,
FrecuenciaRespiratoria = FrecuenciaRespiratoria,
SaturacionOxigeno = SaturacionOxigeno,
Glucosa = Glucosa,
Leucocitos = Leucocitos,
Hemoglobina = Hemoglobina,
Plaquetas = Plaquetas,
Colesterol = Colesterol,
HDL = HDL,
LDL = LDL,
Trigliceridos = Trigliceridos,
Sodio = Sodio,
Potasio = Potasio,
Cloro = Cloro,
Creatinina = Creatinina,
Urea = Urea,
AST = AST,
ALT = ALT,
Bilirrubina = Bilirrubina,
pH = pH,
pCO2 = pCO2,
pO2 = pO2,
HCO3 = HCO3,
Lactato = Lactato
)
),
.groups = "drop"
)
# Convertir a JSON
json_result <- toJSON(df_grouped, pretty = TRUE, auto_unbox = TRUE)
# Mostrar el resultado JSON
cat(json_result)
View(df_grouped)
View(df_grouped[[2]][[1]])
View(df_grouped[[2]][[2]])
View(df_grouped[[2]][[1]])
write.csv(df_grouped,"resumen_evolucion_json.csv")
df_flattened <- df_grouped %>%
unnest(cols = c(registros))
# Guardar el resultado en un archivo CSV
write.csv(df_flattened, "output.csv", row.names = FALSE)
write_json(json_result,"datos_evolucion.json")
data_pac <- data.entry(JSON=df_grouped[2])
data_pac <- data.frame(JSON=df_grouped[2])
View(data_pac)
View(data_pac[[1]][[1]])
data_pac <- data.frame(JSON=json_result)
View(resumen_evolucion_process)
View(resumen_evolucion_process)
library(arules)
install.packages("arulesViz")
