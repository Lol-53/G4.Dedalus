setwd("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion")
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/ReglaAsociacionSYMBI.R", echo=TRUE)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/ReglaAsociacionSYMBI.R", echo=TRUE)
symbipredict_2022 <- read.csv("CSV/symbipredict_2022.csv")
library(fcaR)
symbipredict_2022 <- FormalContext$new(symbipredict_2022[1:100,])
symbipredict_2022
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
symbipredict_2022$plot()
planets
class(planets)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
View(Groceries)
reg <- apriori(symbipredict_2022[1:100,])
symbipredict_2022 <- symbipredict_2022[,:-1]
symbipredict_2022 <- symbipredict_2022[,:1]
symbipredict_2022 <- symbipredict_2022[-c("prognosis")]
symbipredict_2022 <- symbipredict_2022[,-1]
symbipredict_2022 <- read.csv("CSV/symbipredict_2022.csv")
symbipredict_2022 <- symbipredict_2022[,-1]
reg <- apriori(symbipredict_2022[1:100,])
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
symbipredict_2022$fluid_overload <- NULL
symbipredict_2022 <- symbipredict_2022[,-1]
reg <- apriori(symbipredict_2022[1:100,])
table(symbipredict_2022$joint_pain)
symbipredict_2022$joint_pain <- as.factor(symbipredict_2022$joint_pain)  # O usar as.logical si solo tiene 0 y 1
symbipredict_2022 <- symbipredict_2022[,-1]
reg <- apriori(symbipredict_2022[1:100,])
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
# Si deseas establecer manualmente los cortes:
symbipredict_2022$joint_pain_disc <- cut(symbipredict_2022$joint_pain, levels=c(0, 1), labels=c("no", "si"))
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
symbipredict_2022$joint_pain <- NULL
reg <- apriori(symbipredict_2022)
symbipredict_2022$weight_gain <- NULL
reg <- apriori(symbipredict_2022)
symbipredict_2022$anxiety <- NULL
reg <- apriori(symbipredict_2022)
# Ver cuántos valores únicos tiene cada columna
unique_counts <- sapply(df, function(x) length(unique(x)))
Disease_symptom_and_patient_profile_dataset <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/CSV/archive/Disease_symptom_and_patient_profile_dataset.csv")
View(Disease_symptom_and_patient_profile_dataset)
rules <- apriori(Disease_symptom_and_patient_profile_dataset)
View(rules)
inspect(head(rules))
df <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/CSV/archive/Disease_symptom_and_patient_profile_dataset.csv")
str(df)
df[] <- lapply(df,factor)
View(df)
View(df)
str(df)
rules <- apriori(Disease_symptom_and_patient_profile_dataset)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
rules <- apriori(df, parameter = list(support = 0.05, confidence = 0.6))
inspect(head(rules))
inspect(rules)
clean
clr
cl
View(rules)
rules <- apriori(df, parameter = list(support = 0.5, confidence = 0.6))
inspect(head(rules))
rules <- apriori(df, parameter = list(support = 0.3, confidence = 0.6))
inspect(head(rules))
inspect(head(rules,10))
rules <- apriori(df, parameter = list(support = 0.01, confidence = 0.5))
inspect(head(rules,10))
inspect(rules)
# Ver las reglas filtradas
inspect(head(strong_rules))
# Filtrar las reglas con un soporte mínimo de 0.02 y confianza de 0.6
strong_rules <- subset(rules, support >= 0.02 & confidence >= 0.6)
# Ver las reglas filtradas
inspect(head(strong_rules))
# Ver las reglas filtradas
inspect(tail(strong_rules))
inspect(head(strong_rules_lift))
# Filtrar reglas con un Lift mayor a 3 (indica una relación fuerte entre A y B)
strong_rules_lift <- subset(rules, lift > 3)
inspect(head(strong_rules_lift))
inspect(head(strong_rules_lift,20))
# Filtrar reglas que contienen 'disease' en el antecedente o consecuente
rules_with_disease <- subset(rules, subset = lhs %in% "disease" | rhs %in% "disease")
# Filtrar reglas que contienen 'disease' en el antecedente o consecuente
rules_with_disease <- subset(rules, subset = lhs %in% "Disease" | rhs %in% "disease")
# Filtrar reglas que contienen 'disease' en el antecedente o consecuente
rules_with_disease <- subset(rules, subset = lhs %in% "Disease" | rhs %in% "Disease")
library(arules)
df <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/CSV/archive/Disease_symptom_and_patient_profile_dataset.csv")
str(df)
df[] <- lapply(df,factor)
trans <- as(df, "transactions")
View(trans)
rules <- apriori(trans, parameter = list(support = 0.01, confidence = 0.5))
inspect(head(rules,10))
inspect(rules)
# Filtrar las reglas con un soporte mínimo de 0.02 y confianza de 0.6
strong_rules <- subset(rules, support >= 0.02 & confidence >= 0.6)
# Ver las reglas filtradas
inspect(tail(strong_rules))
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/FormalContextSYMBI.R", echo=TRUE)
strong_rules_lift_df <- as.data.frame(strong_rules_lift)
strong_rules_lift_df <- as(strong_rules_lift,"data.frame")
library(jsonlite)
# Convertir el data frame a JSON
rules_json <- toJSON(rules_df, pretty = TRUE)
# Convertir el data frame a JSON
rules_json <- toJSON(strong_rules_lift_df, pretty = TRUE)
# Guardar el JSON en un archivo
write(rules_json, file = "rules.json")
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/consultaProfesor.R", echo=TRUE)
str(df)
df <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/CSV/archive/Disease_symptom_and_patient_profile_dataset.csv")
str(df)
df <- lapply(df, factor)
library(arules)
library(jsonlite)
df <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/CSV/archive/Disease_symptom_and_patient_profile_dataset.csv")
#Observar características de la función
str(df)
df$Age <- ordered(cut(df[[ "Age"]], c(15,25,45,65,100)),
labels = c("Young", "Middle-aged", "Senior", "Old"))
#Procedemos a transformar las columnas a factor previamente verificado que no hay variables continuas
df <- lapply(df, factor)
View(df)
trans <- as(df,"transactions")
View(trans)
rules <- apriori(trans, parameter = list(support = 0.05, confidence = 0.6))
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/consultaProfesor.R", echo=TRUE)
library(arules)
library(jsonlite)
df <- read.csv("CSV/archive/Disease_symptom_and_patient_profile_dataset.csv")
#Observar características de la función
str(df)
df$Age <- ordered(cut(df[[ "Age"]], c(15,25,45,65,100)),
labels = c("Young", "Middle-aged", "Senior", "Old"))
#Procedemos a transformar las columnas a factor previamente verificado que no hay variables continuas
df[] <- lapply(df, factor)
str(df)
trans <- as(df,"transactions")
rules <- apriori(trans)
View(rules)
inspect(head(rules))
rules <- apriori(trans, parameter = list(support = 0.01, confidence = 0.5))
rules_1 <- apriori(trans)
rules_2 <- apriori(trans, parameter = list(support = 0.01, confidence = 0.5))
rules<- apriori(trans)
View(rules_1)
rules_1 <- NULL
View(trans)
rules_subset_1 <- subset(rules, support >= 0.02 & confidence >= 0.6)
rules_subset_2 <- subset(rules, lift>0.3)
View(rules_subset_2)
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/consultaProfesor.R", echo=TRUE)
rules_subset_1_json <- toJSON(rules_subset_1_df, pretty = TRUE)
write(rules_subset_1, file = "rules_subset_1.json")
rules_subset_1 <- subset(rules, support >= 0.02 & confidence >= 0.6)
rules_subset_1_df <- as(rules_subset_1,"data.frame")
rules_subset_1_json <- toJSON(rules_subset_1_df, pretty = TRUE)
write(rules_subset_1, file = "rules_subset_1.json")
rules_subset_1 <- subset(rules, support >= 0.02 & confidence >= 0.6)
inspect(head(rules_subset_1))
rules_subset_2 <- subset(rules, lift>0.3)
inspect(head(rules_subset_1))
rules_subset_1_df <- as(rules_subset_1,"data.frame")
rules_subset_2_df <- as(rules_subset_2,"data.frame")
rules_subset_1_json <- toJSON(rules_subset_1_df, pretty = TRUE)
rules_subset_2_json <- toJSON(rules_subset_2_df, pretty = TRUE)
write(rules_subset_1, file = "rules_subset_1.json")
write(rules_subset_2, file = "rules_subset_2.json")
View(rules_subset_1_df)
View(rules_subset_1)
View(rules_df)
rules_subset_1_df <- as(rules_subset_1,"data.frame")
rules_subset_1_json <- toJSON(rules_subset_1_df, pretty = TRUE)
cat(rules_subset_1_json)
write(rules_subset_1, file = "rules_subset_1.json")
source("C:/Users/mpord/Documents/3IngSoft/2Cuatri/G4.Dedalus/ReglasDeAsociacion/R/consultaProfesor.R", echo=TRUE)
v <- c(1,2,3) +c(5,6,7,8)
v
mean(v)
v1 <- c(1,c(2,c(3,4,5)),1:3)
v1 <- c(v1,v1,c(1,NA))
length(v1)
Cyber.Security.Breaches <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/LCC/DataSet/Cyber Security Breaches.csv", comment.char="#")
View(Cyber.Security.Breaches)
Cyber.Security.Breaches$Name_of_Covered_Entity |>unique()|> length()
Cyber.Security.Breaches$Name_of_Covered_Entity |>unique()
Cyber.Security.Breaches <- read.csv("C:/Users/mpord/Documents/3IngSoft/2Cuatri/LCC/Cyber Security Breaches.csv", comment.char="#")
diff_states <-  Cyber.Security.Breaches$State |> unique() |> length()
diff_states
entidades <- Cyber.Security.Breaches |>
group_by(Cyber.Security.Breaches$Type_of_Breach) |>
summarise(n= n()) |>
arrange(desc(n))
source("C:/Users/mpord/Downloads/Ejercicio1_evaluable (1).R", echo=TRUE)
Cyber.Security.Breaches |>
group_by(Cyber.Security.Breaches$Type_of_Breach) |>
summarise(n= n()) |>
arrange(desc(n))
Cyber.Security.Breaches |>
group_by(Cyber.Security.Breaches$Type_of_Breach) |>
summarise(n= n()) |>
arrange(desc(n))
library(dplyr)
Cyber.Security.Breaches |>
group_by(Cyber.Security.Breaches$Type_of_Breach) |>
summarise(n= n()) |>
arrange(desc(n))
Cyber.Security.Breaches |>
group_by(Type_of_Breach) |>
filter(Type_of_Breach== "Theft, Loss, Unauthorized Access/Disclosure, Unknown") |>
summarise(mean(Individuals_Affected))
source("~/.active-rstudio-document", echo=TRUE)
Cyber.Security.Breaches |>
filter(Cyber.Security.Breaches$Location_of_Breached_Information== "Laptop,Other Portable Electronic Device")
filtered |>
distinct(Type_of_Breach)|>
count()
filtered <- Cyber.Security.Breaches |>
filter(Cyber.Security.Breaches$Location_of_Breached_Information== "Laptop,Other Portable Electronic Device")
filtered |>
distinct(Type_of_Breach)|>
count()
Cyber.Security.Breaches |>
filter(Cyber.Security.Breaches$Location_of_Breached_Information== "Laptop,Other Portable Electronic Device")
distinct(Type_of_Breach)
media <- Cyber.Security.Breaches |>
group_by(Type_of_Breach) |>
filter(Type_of_Breach== "Unauthorized Access/Disclosure, Hacking/IT Incident") |>
summarise(mean(Individuals_Affected, na.rm=TRUE))
Cyber.Security.Breaches |>
group_by(Type_of_Breach) |>
filter(Type_of_Breach== "Theft, Loss, Unauthorized Access/Disclosure, Unknown") |>
summarise(mean(Individuals_Affected,na.rm=TRUE))
Cyber.Security.Breaches |>
group_by(Location_of_Breached_Information) |>
filter(Location_of_Breached_Information== "Laptop,Other Portable Electronic Device") |>
summarise(count(Type_of_Breach))
Cyber.Security.Breaches |>
group_by(Location_of_Breached_Information) |>
filter(Location_of_Breached_Information== "Laptop,Other Portable Electronic Device") |>
summarise(count())
Cyber.Security.Breaches |>
group_by(Location_of_Breached_Information)
Cyber.Security.Breaches |>
filter(Location_of_Breached_Information = "Laptop,Other Portable Electronic Device") |>
distinct(Type_of_Breach) |>
count()
Cyber.Security.Breaches |>
filter(Location_of_Breached_Information == "Laptop,Other Portable Electronic Device") |>
distinct(Type_of_Breach) |>
count()
View(Cyber.Security.Breaches)
reticulate::repl_python()
View(rules_subset_2_df)
